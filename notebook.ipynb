{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c809cdf-aa63-4fdf-acaf-9b79f3ca787a",
   "metadata": {},
   "source": [
    "# Google Gen AI SDK Experimentation\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee784be-66c8-4a2d-bed9-03c87edb2dd8",
   "metadata": {},
   "source": [
    "## SDK Documentation\n",
    "\n",
    "**GitHub**: https://github.com/google-gemini/generative-ai-python\n",
    "\n",
    "\n",
    "**Official Docs**: https://ai.google.dev/gemini-api/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0d708-a7a2-48a0-ab7c-50ab6cea415c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45a61dfa-9a32-44d7-aaca-3f1c28beacff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file in the current directory\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c88740-5b6e-4437-b78a-ebd754e7187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4694eb0-080a-4c90-996c-c15b2d9fac1a",
   "metadata": {},
   "source": [
    "## Text generation\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/text-generation?lang=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b294b490-376e-411f-9e11-6555c6ff1d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLHF (Reinforcement Learning from Human Feedback) improves AI models by using human preferences to refine their responses. Here's the process:\n",
      "\n",
      "1. **Collect Data:** Humans provide feedback (e.g., ranking or rating) on different AI-generated responses to the same prompt.\n",
      "2. **Train Reward Model:** A model learns to predict human preferences based on the collected feedback.\n",
      "3. **Reinforcement Learning:** The AI model is then trained using reinforcement learning to maximize the reward predicted by the reward model, thus generating responses that align better with human preferences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash', contents='How does RLHF work? Keep it short.'\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50097308-aeb9-48ad-90b8-05cc49e6b2dd",
   "metadata": {},
   "source": [
    "## Vision\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/vision?lang=python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb88f46-bec0-46dc-9479-90d58dd614ba",
   "metadata": {},
   "source": [
    "### Inline Data Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7055281-d4da-4d92-9b90-dfbc1c529569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f310dbb-5f73-4f80-9af8-2ffccc056493",
   "metadata": {},
   "source": [
    "### File API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd18762-1808-4685-8974-cccf6bb644e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b290a8-336b-4474-accc-a0fc832a92cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8f7a771-207d-4b00-8c71-dd8f9a4b6eed",
   "metadata": {},
   "source": [
    "## Count Tokens\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/tokens?lang=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e937c635-b6cd-45ee-a6c5-828d37eb214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.count_tokens(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents='The quick brown fox jumps over the lazy dog.',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f3462a-89bc-4821-9682-1234b7ad42b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountTokensResponse(total_tokens=11, cached_content_token_count=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "836155f1-775a-4812-bf97-38770a6d50dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337bbbc-233d-4c22-addf-0f89286a6db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "827c5da4-3e47-4707-8f50-3610882de3cf",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/structured-output?lang=python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b690d3ec-9062-4c4e-9c24-099c151e5322",
   "metadata": {},
   "source": [
    "Using `genai.types.Schema` (can also pass equivalent `dict`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c29099b-a36d-47bc-92fe-e9e8f2b82ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "# import os\n",
    "# from google import genai\n",
    "# from google.genai import types\n",
    "\n",
    "\n",
    "# def generate():\n",
    "#     client = genai.Client(\n",
    "#         api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "#     )\n",
    "\n",
    "#     model = \"gemini-2.0-flash\"\n",
    "#     contents = [\n",
    "#         types.Content(\n",
    "#             role=\"user\",\n",
    "#             parts=[\n",
    "#                 types.Part.from_text(\n",
    "#                     text=\"Provide a detailed recipe for a delicious pasta dish\"\n",
    "#                 ),\n",
    "#             ],\n",
    "#         ),\n",
    "#     ]\n",
    "#     generate_content_config = types.GenerateContentConfig(\n",
    "#         temperature=1,\n",
    "#         top_p=0.95,\n",
    "#         top_k=40,\n",
    "#         max_output_tokens=8192,\n",
    "#         response_mime_type=\"application/json\",\n",
    "#         response_schema=genai.types.Schema(\n",
    "#             type=genai.types.Type.OBJECT,\n",
    "#             enum=[],\n",
    "#             required=[\"summary\", \"instructions\"],\n",
    "#             properties={\n",
    "#                 \"summary\": genai.types.Schema(\n",
    "#                     type=genai.types.Type.STRING,\n",
    "#                 ),\n",
    "#                 \"instructions\": genai.types.Schema(\n",
    "#                     type=genai.types.Type.ARRAY,\n",
    "#                     items=genai.types.Schema(\n",
    "#                         type=genai.types.Type.STRING,\n",
    "#                     ),\n",
    "#                 ),\n",
    "#             },\n",
    "#         ),\n",
    "#     )\n",
    "\n",
    "#     # Uncomment the streaming version if needed (does not work properly in a notebook environment):\n",
    "#     # for chunk in client.models.generate_content_stream(\n",
    "#     #     model=model,\n",
    "#     #     contents=contents,\n",
    "#     #     config=generate_content_config,\n",
    "#     # ):\n",
    "#     #     print(chunk.text, end=\"\")\n",
    "\n",
    "#     # Use the non-streaming API call instead:\n",
    "#     response = client.models.generate_content(\n",
    "#         model=model,\n",
    "#         contents=contents,\n",
    "#         config=generate_content_config,\n",
    "#     )\n",
    "#     # print(response.text)\n",
    "#     return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c26278-1f0e-4187-82cf-6edccc942049",
   "metadata": {},
   "source": [
    "Using *Pydantic* schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37c4ec83-5577-4d2f-87e8-135475805bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# Example Pydantic schema for reference\n",
    "# -------------------------------------\n",
    "class RecipeResponse(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    instructions: List[str]\n",
    "\n",
    "\n",
    "# Example with optional field for reference\n",
    "# -----------------------------------------\n",
    "# from typing import Optional\n",
    "\n",
    "# class RecipeResponse(BaseModel):\n",
    "#     title: Optional[str] = None  # now optional\n",
    "#     summary: str\n",
    "#     instructions: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3075e51b-a275-4026-a3e3-f6329b0c68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "def generate():\n",
    "    client = genai.Client(\n",
    "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    model = \"gemini-2.0-flash\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part.from_text(\n",
    "                    text=\"Provide a detailed recipe for a delicious chicken dish\"\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    # Use the Pydantic schema directly in response_schema.\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=1,\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "        max_output_tokens=8192,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=RecipeResponse,\n",
    "    )\n",
    "\n",
    "    # Use the non-streaming API call.\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83a2d9c4-0fc0-465f-aa8e-a8f8cffa9474",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daf25a71-88ff-4412-ad67-fee28ce12ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.genai.types.GenerateContentResponse"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c4451b-3d23-49b6-adbe-4a3b5eaceca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "415d05cb-038d-4c19-bae7-45abd8557451",
   "metadata": {},
   "source": [
    "`result.text` is a raw JSON string—you get exactly what the API returned as text. It's of type str and shows the full JSON output, which you might want to log or inspect directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e63ac6d-3bae-4d02-858b-6682bdc0d341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response text:\n",
      "\n",
      "{\n",
      "  \"title\": \"Lemon Herb Roasted Chicken\",\n",
      "  \"summary\": \"A flavorful and juicy whole roasted chicken infused with lemon, herbs, and garlic. Perfect for a weeknight dinner or a special occasion.\",\n",
      "  \"instructions\": [\n",
      "    \"Preheat oven to 425°F (220°C).\",\n",
      "    \"Rinse a 3-4 pound whole chicken inside and out and pat dry with paper towels. Remove giblets and neck, if present.\",\n",
      "    \"In a small bowl, combine 2 tablespoons of softened butter, 2 cloves minced garlic, zest of 1 lemon, 1 tablespoon chopped fresh rosemary, 1 tablespoon chopped fresh thyme, 1/2 teaspoon salt, and 1/4 teaspoon black pepper.\",\n",
      "    \"Loosen the skin of the chicken breast and rub half of the herb butter mixture underneath the skin, directly onto the breast meat. Rub the remaining herb butter all over the outside of the chicken.\",\n",
      "    \"Place the chicken in a roasting pan. Stuff the cavity with the halved lemon and the remaining herb sprigs.\",\n",
      "    \"Tie the chicken legs together with kitchen twine.\",\n",
      "    \"Roast for 1 hour and 15 minutes to 1 hour and 30 minutes, or until a meat thermometer inserted into the thickest part of the thigh registers 165°F (74°C).\",\n",
      "    \"Let the chicken rest for 10-15 minutes before carving and serving.\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw response text:\\n\")\n",
    "print(result.text)\n",
    "print(\"\")\n",
    "print(type(result.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333d5ae-e00e-4d77-a805-f5e3ff7f1900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b89e2f3-70c6-4519-8dbd-065d86e7aa08",
   "metadata": {},
   "source": [
    "`result.parsed` is the same data, but automatically converted into a structured Python object based on the schema you provided—in this case, an instance of your RecipeResponse Pydantic model. This lets you work with the data using native Python attributes (for example, accessing parsed.summary directly) and ensures that the data conforms to your expected structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2253490f-490a-478f-9faf-d0c9b1a7a926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed response as RecipeResponse instance:\n",
      "\n",
      "title='Lemon Herb Roasted Chicken' summary='A flavorful and juicy whole roasted chicken infused with lemon, herbs, and garlic. Perfect for a weeknight dinner or a special occasion.' instructions=['Preheat oven to 425°F (220°C).', 'Rinse a 3-4 pound whole chicken inside and out and pat dry with paper towels. Remove giblets and neck, if present.', 'In a small bowl, combine 2 tablespoons of softened butter, 2 cloves minced garlic, zest of 1 lemon, 1 tablespoon chopped fresh rosemary, 1 tablespoon chopped fresh thyme, 1/2 teaspoon salt, and 1/4 teaspoon black pepper.', 'Loosen the skin of the chicken breast and rub half of the herb butter mixture underneath the skin, directly onto the breast meat. Rub the remaining herb butter all over the outside of the chicken.', 'Place the chicken in a roasting pan. Stuff the cavity with the halved lemon and the remaining herb sprigs.', 'Tie the chicken legs together with kitchen twine.', 'Roast for 1 hour and 15 minutes to 1 hour and 30 minutes, or until a meat thermometer inserted into the thickest part of the thigh registers 165°F (74°C).', 'Let the chicken rest for 10-15 minutes before carving and serving.']\n",
      "\n",
      "<class '__main__.RecipeResponse'>\n"
     ]
    }
   ],
   "source": [
    "# The SDK should automatically parse the JSON into an instance of RecipeResponse.\n",
    "parsed = result.parsed\n",
    "print(\"\\nParsed response as RecipeResponse instance:\\n\")\n",
    "print(parsed)\n",
    "print(\"\")\n",
    "print(type(parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01066138-6fb4-4a5c-bd42-dab981e119be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1312c72f-7615-47df-9c03-8a9bd8f9bdfb",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "Use `result.text` when you need the raw JSON (for logging or debugging) and `result.parsed` when you want the validated, typed object for further processing in your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea71b84-f5d1-42a1-ba84-8da25070c3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f98121e1-6ade-4e9a-ba3b-108a3d1f972d",
   "metadata": {},
   "source": [
    "If you're already using the SDK’s automatic parsing (i.e. using `result.parsed`), then the JSON has already been parsed and validated against your Pydantic schema. In that case, calling an additional validation function is usually redundant.\n",
    "\n",
    "The function `validate_json_respons` is designed to take a raw JSON string (like what you'd get from `result.text`) and manually validate it against a provided Pydantic model. But since the SDK does that for you when you supply the schema in the configuration, there's generally no need to pass anything extra to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67133561-b69f-4ccc-8592-0655726529bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Type, Tuple, Optional\n",
    "import json\n",
    "\n",
    "\n",
    "def validate_json_response(response_text: str, schema: Type[BaseModel]) -> Tuple[bool, Optional[BaseModel]]:\n",
    "    \"\"\"\n",
    "    Validates that the given response_text is valid JSON and adheres to the provided Pydantic schema.\n",
    "    \n",
    "    Parameters:\n",
    "        response_text (str): The raw JSON string to validate.\n",
    "        schema (Type[BaseModel]): The Pydantic schema to validate against.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[bool, Optional[BaseModel]]: A tuple where the first element is True if the JSON is valid and adheres to the schema,\n",
    "                                           and the second element is the validated Pydantic model instance (or the raw data if validation fails).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(response_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Invalid JSON:\", e)\n",
    "        return False, None\n",
    "\n",
    "    # Print the schema details we're validating against:\n",
    "    schema_json = json.dumps(schema.model_json_schema(), indent=2)\n",
    "    print(\"Validating against schema:\")\n",
    "    print(schema_json)\n",
    "    \n",
    "    try:\n",
    "        # Use model_validate (Pydantic v2) instead of parse_obj\n",
    "        validated_data = schema.model_validate(data)\n",
    "    except Exception as e:\n",
    "        print(\"Schema validation failed:\", e)\n",
    "        return False, data\n",
    "\n",
    "    # print(\"Response is valid and adheres to the schema.\")\n",
    "    return True, validated_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c054a7da-4ce1-432b-b14a-3828adb79440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating against schema:\n",
      "{\n",
      "  \"properties\": {\n",
      "    \"title\": {\n",
      "      \"title\": \"Title\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"summary\": {\n",
      "      \"title\": \"Summary\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"instructions\": {\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Instructions\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"title\",\n",
      "    \"summary\",\n",
      "    \"instructions\"\n",
      "  ],\n",
      "  \"title\": \"RecipeResponse\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "Validation successful!\n"
     ]
    }
   ],
   "source": [
    "# Call generate() to get the response JSON string\n",
    "result = generate()\n",
    "\n",
    "# raw JSON string\n",
    "raw_response = result.text\n",
    "\n",
    "# Validate the JSON response using the RecipeResponse schema\n",
    "is_valid, validated_model = validate_json_response(raw_response, RecipeResponse)\n",
    "\n",
    "if is_valid:\n",
    "    print(\"Validation successful!\")\n",
    "    # Pretty-print the validated model using json.dumps on model_dump()\n",
    "    # print(json.dumps(validated_model.model_dump(), indent=2))\n",
    "else:\n",
    "    print(\"Validation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661d256c-085d-4408-b5f3-4a010c16733d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dacdfbe-fa57-44a1-b1b7-ab9233c6ddd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59201f4c-3acb-46c3-84e6-1c83bab0d99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b374d3-b0fd-4228-ad0a-3739d137d387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03b9b046-efe2-4129-9c0f-362c0e9c66a4",
   "metadata": {},
   "source": [
    "## Function calling\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/function-calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f4fd9-00d6-465f-a986-8d26088867e1",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa0d9b-99e3-4f79-a9b3-b04fb25832b8",
   "metadata": {},
   "source": [
    "Automatic function calling is the default. Here we disable it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6656ac24-1a93-449c-9730-a7cecba4d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marabian/Notebooks/google-genai-sdk-notebooks/.venv/lib/python3.12/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `enum` but got `str` with value `'STRING'` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client()\n",
    "\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Get the current whether in a given location.\n",
    "\n",
    "    Args:\n",
    "        location: required, The city and state, e.g. San Franciso, CA\n",
    "        unit: celsius or fahrenheit\n",
    "    \"\"\"\n",
    "    print(f'Called with: {location=}')\n",
    "    return \"23C\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "   model='gemini-2.0-flash',\n",
    "   contents=\"What is the weather like in Boston?\",\n",
    "   config=types.GenerateContentConfig(\n",
    "       tools=[get_current_weather],\n",
    "       automatic_function_calling={'disable': True},\n",
    "   ),\n",
    ")\n",
    "\n",
    "function_call = response.candidates[0].content.parts[0].function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bb99f80-f132-4e79-8cee-c4b17243ab73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(id=None, args={'location': 'Boston, MA'}, name='get_current_weather')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2226489a-095e-4990-b5f9-6eb074337e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function call details: id=None args={'location': 'Boston, MA'} name='get_current_weather'\n",
      "Called with: location='Boston, MA'\n",
      "Function call result: 23C\n"
     ]
    }
   ],
   "source": [
    "# New cell to execute the function call extracted from the response\n",
    "if function_call:\n",
    "    print(\"Function call details:\", function_call)\n",
    "    # Extract the function name and arguments\n",
    "    func_name = function_call.name\n",
    "    func_args = function_call.args\n",
    "\n",
    "    # Based on the function name, call the appropriate function with the provided arguments.\n",
    "    if func_name == \"get_current_weather\":\n",
    "        result = get_current_weather(**func_args)\n",
    "        print(\"Function call result:\", result)\n",
    "    else:\n",
    "        print(\"No matching function found for\", func_name)\n",
    "else:\n",
    "    print(\"No function call detected in the response.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1482d1d7-0057-4825-9d45-eb666db19833",
   "metadata": {},
   "source": [
    "### Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fb12c5b-5819-4f25-bac8-8f2edd5c094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client()\n",
    "\n",
    "def get_current_weather(city: str) -> str:\n",
    "    return \"23C\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "   model='gemini-2.0-flash',\n",
    "   contents=\"What is the weather like in Boston?\",\n",
    "   config=types.GenerateContentConfig(\n",
    "       tools=[get_current_weather] \n",
    "   ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03d81ac3-38fb-4b42-af3d-52447cacbc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is 23C in Boston.\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb615462-9969-4dd9-8995-615b9e32a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cowsay\n",
    "\n",
    "# import cowsay  # Ensure you have installed cowsay via pip\n",
    "\n",
    "# def generate_cowsay(text: str) -> str:\n",
    "#     # Use cowsay.cow instead of cowsay.cowsay\n",
    "#     return cowsay.cow(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1effa8f-48dd-4f8d-9d0e-d94852e0d916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58638b5f-a191-44de-b65b-2ce295fde100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfb6c1-ebe7-47db-bb44-d12e5762f166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da27f12d-d480-444e-b249-0208edab82f9",
   "metadata": {},
   "source": [
    "## Code Execution\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/code-execution?lang=python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59941d01-3f20-4e61-858d-9f1dca8cb3d9",
   "metadata": {},
   "source": [
    "### Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc1bc04a-b1ab-4551-85e0-8ca8630a563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "  model='gemini-2.0-flash',\n",
    "  contents='What is the sum of the first 50 prime numbers? '\n",
    "           'Generate and run code for the calculation, and make sure you get all 50.',\n",
    "  config=types.GenerateContentConfig(\n",
    "    tools=[types.Tool(\n",
    "      code_execution=types.ToolCodeExecution\n",
    "    )]\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a75643bf-3dd9-4b64-a438-b83f73eb38b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, I need to find the sum of the first 50 prime numbers. Here's my plan:\n",
       "\n",
       "1.  Generate a list of prime numbers until I have 50 of them.\n",
       "2.  Calculate the sum of those 50 prime numbers.\n",
       "\n",
       "Here's the Python code to do that:\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"background-color: #BBBBEE;\">def is_prime(n):\n",
       "    \"\"\"Efficiently determine if a number is prime.\"\"\"\n",
       "    if n <= 1:\n",
       "        return False\n",
       "    if n <= 3:\n",
       "        return True\n",
       "    if n % 2 == 0 or n % 3 == 0:\n",
       "        return False\n",
       "    i = 5\n",
       "    while i * i <= n:\n",
       "        if n % i == 0 or n % (i + 2) == 0:\n",
       "            return False\n",
       "        i += 6\n",
       "    return True\n",
       "\n",
       "def sum_first_n_primes(n):\n",
       "    \"\"\"Calculate the sum of the first n prime numbers.\"\"\"\n",
       "    primes = []\n",
       "    num = 2\n",
       "    while len(primes) < n:\n",
       "        if is_prime(num):\n",
       "            primes.append(num)\n",
       "        num += 1\n",
       "    return sum(primes)\n",
       "\n",
       "result = sum_first_n_primes(50)\n",
       "print(f'{result=}')\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "result=5117\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The sum of the first 50 prime numbers is 5117.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, HTML, Image\n",
    "\n",
    "def display_code_execution_result(response):\n",
    "  for part in response.candidates[0].content.parts:\n",
    "    if part.text is not None:\n",
    "      display(Markdown(part.text))\n",
    "    if part.executable_code is not None:\n",
    "      code_html = f'<pre style=\"background-color: #BBBBEE;\">{part.executable_code.code}</pre>' # Change code color\n",
    "      display(HTML(code_html))\n",
    "    if part.code_execution_result is not None:\n",
    "      display(Markdown(part.code_execution_result.output))\n",
    "    if part.inline_data is not None:\n",
    "      display(Image(data=part.inline_data.data, format=\"png\"))\n",
    "    display(Markdown(\"---\"))\n",
    "\n",
    "display_code_execution_result(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6472c2-3942-45ab-a58b-053fd3a7c3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfda7aa-7f14-4f76-9baf-06314eae58e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a960bac-b92a-4555-9b1c-a603d022d912",
   "metadata": {},
   "source": [
    "### Interleaving Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92a41d3f-6728-4cf5-961b-63a17a67f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=(\n",
    "        \"Please do the following in one response:\\n\\n\"\n",
    "        \"Calculation 1: Write and run code that calculates the sum of the numbers from 1 to 10.\\n\"\n",
    "        \"Text Output: After the first calculation, output the text message: 'The sum of 1 through 10 has been computed successfully!'\\n\"\n",
    "        \"Calculation 2: Then, write and run code that calculates the factorial of 6.\\n\"\n",
    "        \"Make sure the response interleaves the code outputs with the text message accordingly.\"\n",
    "    ),\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[types.Tool(\n",
    "            code_execution=types.ToolCodeExecution\n",
    "        )]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e3445f5-c3ca-4822-a08f-06010dc85422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"background-color: #BBBBEE;\">sum_result = sum(range(1, 11))\n",
       "print(f'{sum_result=}')\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "sum_result=55\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The sum of 1 through 10 has been computed successfully!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"background-color: #BBBBEE;\">import math\n",
       "factorial_result = math.factorial(6)\n",
       "print(f'{factorial_result=}')\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "factorial_result=720\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I have now completed both calculations and interspersed the output messages as requested.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_code_execution_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99afc14a-7c84-4fef-ade3-e96b8f498c30",
   "metadata": {},
   "source": [
    "### Input/output (I/O)\n",
    "\n",
    "Starting with Gemini 2.0 Flash, code execution supports file input and graph output. Using these new input and output capabilities, you can upload CSV and text files, ask questions about the files, and have Matplotlib graphs generated as part of the response.\n",
    "\n",
    "\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/code-execution?lang=python#input-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257a3ff-18ad-4541-aeb7-57ff4148638c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5b31c62-f674-4229-816f-5aef29ffca73",
   "metadata": {},
   "source": [
    "## Search grounding\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/grounding?lang=python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b60aeb-c1c4-47dd-87ab-2d5a6dca5d00",
   "metadata": {},
   "source": [
    "`GoogleSearch` (Gemini>=2.0) and `GoogleSearchRetrieval` (Gemini < 2.0) are tools that allow the model to retrieve public web data for grounding, powered by Google.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1bb0ba8d-327b-4bdc-8945-92e0ce935361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents='What is the Google stock price?',\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[\n",
    "            types.Tool(\n",
    "                google_search=types.GoogleSearch()\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "22eecf7b-0782-4b34-a5da-f847ef73e23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of March 5, 2025, at 8:19 AM UTC, the price of Alphabet Inc. (Google) Class C stock (GOOG) is approximately $172.61. It has decreased by 2.07% in the past 24 hours.\\n'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e704c5f8-763f-44fd-9594-1257c8a61c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_metadata=None thought=None code_execution_result=None executable_code=None file_data=None function_call=None function_response=None inline_data=None text='As of March 5, 2025, the price of Alphabet Inc (Google) Class C (GOOG) is around $172.61.\\nIt has decreased by approximately -2.07% in the past 24 hours.\\n'\n"
     ]
    }
   ],
   "source": [
    "for part in response.candidates[0].content.parts:\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece70414-d6fe-4cff-8552-e2691ba6b048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3884b0e-47f1-481e-b638-60d6b9e96742",
   "metadata": {},
   "source": [
    "## Document Understanding\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/document-processing?lang=python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd01dd-92f3-4f52-859a-4139d15cdf4a",
   "metadata": {},
   "source": [
    "Needs testing for `Gemini 2.0`, docs are for older versions of Gemini.\n",
    "\n",
    "Supports:\n",
    "\n",
    "* PDF - `application/pdf`\n",
    "* JavaScript - `application/x-javascript, text/javascript`\n",
    "* Python - `application/x-python, text/x-python`\n",
    "* TXT - `text/plain`\n",
    "* HTML - `text/html`\n",
    "* CSS - `text/css`\n",
    "* Markdown - `text/md`\n",
    "* CSV - `text/csv`\n",
    "* XML - `text/xml`\n",
    "* RTF - `text/rtf`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c7945-47b1-4f5e-bf13-0a156b51afbb",
   "metadata": {},
   "source": [
    "## Async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bca77-a7e8-460c-ba76-d7b3d151d319",
   "metadata": {},
   "source": [
    "https://github.com/google-gemini/generative-ai-python?tab=readme-ov-file#async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2e544-7037-4571-8289-ccf74d30640d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f8ec93-af0d-44c3-b0ae-710d543ea102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3299e1cc-3ccf-42bc-a49c-6b08b639f202",
   "metadata": {},
   "source": [
    "## Context caching\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe400d4a-3ad9-43c1-bdbf-9578e3b658c6",
   "metadata": {},
   "source": [
    "https://github.com/google-gemini/generative-ai-python?tab=readme-ov-file#context-caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59a59ac-905e-405c-bbc6-f4ba45afab88",
   "metadata": {},
   "source": [
    "## Embed Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d3fff9be-df49-4132-81e4-83a0abdf2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.embed_content(\n",
    "   model='text-embedding-004',\n",
    "   contents='Hello world',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "acea532a-388b-47fd-9529-f82d3287a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d272a-b498-4c58-ae01-3fd9f754bb5a",
   "metadata": {},
   "source": [
    "## Tune a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f50058-fed4-4bc7-b9c6-46ca31bccebb",
   "metadata": {},
   "source": [
    "https://github.com/google-gemini/generative-ai-python?tab=readme-ov-file#tune-a-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de78f59-21cf-4254-90b3-8e0f610c979d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google-genai-sdk-notebooks",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
